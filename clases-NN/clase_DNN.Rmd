---
title: '<span id = "title-text">Redes Neuronales<br> en `Keras` </span>'
author: '<span> <span id = "name" >Alfonso Tobar Arancibia </span> <br><span style = "font-size: 75%;">Data Scientist<br>13-10-2020</span> </span> '
date: '`r icon::fa("github")` [github.com/Rcubes/clases-ml/Slides](https://github.com/Rcubes/clases-ml/tree/master/Slides)'

output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: solarized-dark
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
---


```{r setup, include=FALSE}
library(reticulate)
use_condaenv(condaenv = 'MLprojects')
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(cache=TRUE)
```

```{r xaringan-themer, include=FALSE}
library(xaringanthemer)
solarized_light(
  code_font_family = "Fira Code",
  code_font_url    = "https://cdn.rawgit.com/tonsky/FiraCode/1.204/distr/fira_code.css"
)

```

# Redes Neuronales Densas

El tipo de Redes Neuronales más básicas son las Redes Neuronales densas, también llamadas DNN. Las principales características de este tipo de Redes son que:

* Cada Neurona de entrada mapea un **feature** de los datos. 
* Todas las Neuronas de una capa se encuentran unidas con todas las neuronas de la capa siguiente.
* Se debe utilizar una Neurona por cada valor de salida.

.center[

```{r, echo = FALSE, out.width='50%'}
knitr::include_graphics("img/DNN.png")
```


]

---

# Cargando Keras desde Tensorflow

Keras corresponde a la API de alto nivel que permite crear las arquitecturas de Redes Neuronales más populares. En el caso de querer dedicarse a la investigación y a generar modelos 100% customizados, entonces convendrá trabajar con Tensorflow directamente.

La API de Tensorflow está cambiando rápidamente por lo que es bueno estar revisando la documentación en todo momento. A partir de Tensorflow 2.0, Keras se encuentra integrado. Esto porque en ocasiones anteriores el desarrollo de Keras estaba atrasado y generaba grandes problemas de compatibilidad.


```{python, eval = FALSE}
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
```

Lo primero que debe instanciarse es el tipo de modelo. En nuestro caso será `Sequential()`, y luego se irán agregando capas:

```{python, eval = FALSE}
model = Sequential(name = 'Modelo')
model.add(Dense(name = 'hidden_1', units = 32, input_shape = (10,), activation = 'relu'))
model.add(Dense(name = 'hidden_2', units = 64, activation = 'relu'))
model.add(Dense(name = 'output', units = 1, activation = None))
```


---

# Crear DNN en Keras

```{python, eval = FALSE}
model = Sequential(name = 'Modelo')
```

.pull-left[
* Esto corresponde a instanciar el Modelo. No importa que tipo de Red Neuronal se utilice siempré se utilizará `Sequential()`.


]

.pull-right[
**Pros**: API Extremadamente sencilla.

**Cons**: Sólo permite capas de Neuronas que se aplican de manera secuencial.


]

```{python, eval = FALSE}
model.add(Dense(name = 'hidden_1', units = 32, input_shape = (10,), activation = 'relu'))
```
Se utiliza el método `.add()` junto con la capa a utilizar. En este caso una capa densa, que creará uniones entre todas las neuronas de la capa anterior (en este caso la de entrada) y la actual (en este caso 'hidden_1').

* **name**: Corresponde a un nombre para referirse a cada elemento del modelo. *OJO: No usar espacios*.
* **units**: corresponde al número de neuronas de la capa.
* **input_shape**: Corresponde a un parámetro que se coloca en la primera capa definida en Keras. Este parámetro es una tupla que define cuántas features se utilizarán para el proceso de modelamiento. No es necesario definirlo para las siguientes capas ya que se infiere capa a capa.
* **activation**: Corresponde a la función de activación de la capa. Esta debe ser escogida cuidadosamente dependiendo de su ubicación.

---
# Compilar DNN en Keras

```{python, eval = FALSE}
model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])
```

`.compile()` generará el empaquetamiento final con las características con las que se optimizará y medirá la performance del modelo.

* **loss**: Corresponde a la función de costo. El propósito de esta función es minimizarla lo más posible.
* **optimizer**: Corresponde al proceso de optimización con el que se encontrará los pesos óptimos de tal manera que la red neuronal aprenda.
* **metrics**: Corresponde a la métrica que se utilizará para encontrar el modelo óptimo.

## Entrenar el modelo

```{python, eval = FALSE}
model.fit(X_train, y_train, epochs = 20, validation_split = 0.1, shuffle = True)

```

* **epochs**: Corresponde al número de pasadas de entrenamiento que se utilizarán para entrenar. 
* **validation_split**: Corresponde a un parámetro opcional que genera un split de validación para la búsqueda de hiperparámetros.
* **shuffle**: Permite revolver el dataset antes del split de validación.

---

# Recomendaciones

.pull-left[
```{r, echo = FALSE, out.width='90%'}
knitr::include_graphics("img/recomendacion.PNG")
```


]

.pull-right[

* Usar **relu** sólo en capas ocultas, nunca como capa de salida.
* La capa de entrada en Keras es implicita, por lo tanto no tiene asociada una función de activación.
* No usar función de activación es equivalente a usar una Función Identidad.
* Para problemas de regresión también se puede usar **MAE** tanto como función de Costo como métrica de evaluación.
]


---

class: inverse, center, middle

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br /><span xmlns:dct="http://purl.org/dc/terms/" data-property="dct:title">Estas clases</span> fueron creadas por
<span xmlns:cc="http://creativecommons.org/ns#" data-property="cc:attributionName">Alfonso
Tobar</span> y están licenciadas bajo <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative
Commons Attribution-NonCommercial-ShareAlike 4.0 International
License</a>.










