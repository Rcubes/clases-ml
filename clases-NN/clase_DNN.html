<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Redes Neuronales  en Keras </title>
    <meta charset="utf-8" />
    <meta name="author" content=" Alfonso Tobar Arancibia   Data Scientist 13-10-2020 " />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/font-awesome/css/fontawesome-all.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# <span id="title-text">Redes Neuronales<br> en <code>Keras</code> </span>
### <span> <span id="name">Alfonso Tobar Arancibia </span> <br><span style="font-size: 75%;">Data Scientist<br>13-10-2020</span> </span>
### <i class="fab  fa-github "></i> <a href="https://github.com/Rcubes/clases-ml/tree/master/Slides">github.com/Rcubes/clases-ml/Slides</a>

---







# Redes Neuronales Densas

El tipo de Redes Neuronales más básicas son las Redes Neuronales densas, también llamadas DNN. Las principales características de este tipo de Redes son que:

* Cada Neurona de entrada mapea un **feature** de los datos. 
* Todas las Neuronas de una capa se encuentran unidas con todas las neuronas de la capa siguiente.
* Se debe utilizar una Neurona por cada valor de salida.

.center[

&lt;img src="img/DNN.png" width="50%" /&gt;


]

---

# Cargando Keras desde Tensorflow

Keras corresponde a la API de alto nivel que permite crear las arquitecturas de Redes Neuronales más populares. En el caso de querer dedicarse a la investigación y a generar modelos 100% customizados, entonces convendrá trabajar con Tensorflow directamente.

La API de Tensorflow está cambiando rápidamente por lo que es bueno estar revisando la documentación en todo momento. A partir de Tensorflow 2.0, Keras se encuentra integrado. Esto porque en ocasiones anteriores el desarrollo de Keras estaba atrasado y generaba grandes problemas de compatibilidad.



```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
```

Lo primero que debe instanciarse es el tipo de modelo. En nuestro caso será `Sequential()`, y luego se irán agregando capas:


```python
model = Sequential(name = 'Modelo')
model.add(Dense(name = 'hidden_1', units = 32, input_shape = (10,), activation = 'relu'))
model.add(Dense(name = 'hidden_2', units = 64, activation = 'relu'))
model.add(Dense(name = 'output', units = 1, activation = None))
```


---

# Crear DNN en Keras


```python
model = Sequential(name = 'Modelo')
```

.pull-left[
* Esto corresponde a instanciar el Modelo. No importa que tipo de Red Neuronal se utilice siempré se utilizará `Sequential()`.


]

.pull-right[
**Pros**: API Extremadamente sencilla.

**Cons**: Sólo permite capas de Neuronas que se aplican de manera secuencial.


]


```python
model.add(Dense(name = 'hidden_1', units = 32, input_shape = (10,), activation = 'relu'))
```
Se utiliza el método `.add()` junto con la capa a utilizar. En este caso una capa densa, que creará uniones entre todas las neuronas de la capa anterior (en este caso la de entrada) y la actual (en este caso 'hidden_1').

* **name**: Corresponde a un nombre para referirse a cada elemento del modelo. *OJO: No usar espacios*.
* **units**: corresponde al número de neuronas de la capa.
* **input_shape**: Corresponde a un parámetro que se coloca en la primera capa definida en Keras. Este parámetro es una tupla que define cuántas features se utilizarán para el proceso de modelamiento. No es necesario definirlo para las siguientes capas ya que se infiere capa a capa.
* **activation**: Corresponde a la función de activación de la capa. Esta debe ser escogida cuidadosamente dependiendo de su ubicación.

---
# Compilar DNN en Keras


```python
model.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])
```

`.compile()` generará el empaquetamiento final con las características con las que se optimizará y medirá la performance del modelo.

* **loss**: Corresponde a la función de costo. El propósito de esta función es minimizarla lo más posible.
* **optimizer**: Corresponde al proceso de optimización con el que se encontrará los pesos óptimos de tal manera que la red neuronal aprenda.
* **metrics**: Corresponde a la métrica que se utilizará para encontrar el modelo óptimo.

## Entrenar el modelo


```python
model.fit(X_train, y_train, epochs = 20, validation_split = 0.1, shuffle = True)
```

* **epochs**: Corresponde al número de pasadas de entrenamiento que se utilizarán para entrenar. 
* **validation_split**: Corresponde a un parámetro opcional que genera un split de validación para la búsqueda de hiperparámetros.
* **shuffle**: Permite revolver el dataset antes del split de validación.

---

# Recomendaciones

.pull-left[
&lt;img src="img/recomendacion.PNG" width="90%" /&gt;


]

.pull-right[

* Usar **relu** sólo en capas ocultas, nunca como capa de salida.
* La capa de entrada en Keras es implicita, por lo tanto no tiene asociada una función de activación.
* No usar función de activación es equivalente a usar una Función Identidad.
* Para problemas de regresión también se puede usar mae tanto como función de Costo como métrica de evaluación.
]


---

class: inverse, center, middle

&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;&lt;img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;span xmlns:dct="http://purl.org/dc/terms/" data-property="dct:title"&gt;Estas clases&lt;/span&gt; fueron creadas por
&lt;span xmlns:cc="http://creativecommons.org/ns#" data-property="cc:attributionName"&gt;Alfonso
Tobar&lt;/span&gt; y están licenciadas bajo &lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;Creative
Commons Attribution-NonCommercial-ShareAlike 4.0 International
License&lt;/a&gt;.










    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "solarized-dark",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
