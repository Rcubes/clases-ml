<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Introducción al Modelamiento</title>
    <meta charset="utf-8" />
    <meta name="author" content="Alfonso Tobar" />
    <meta name="date" content="2020-09-21" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Introducción al Modelamiento
## en <code>Scikit-Learn</code>
### Alfonso Tobar
### 2020-09-21

---







# Qué es modelar?

Modelar es describir una realidad utilizando Lenguajes/Conceptos Matemáticos.
Un modelo se utiliza para explicar un sistema, estudiar los efectos de sus componentes y hacer predicciones.

&gt; "...en esencia , todos los modelos están equivocados, pero algunos son útiles..."

*George Edward Pelham Box*



### Qué es Machine Learning?
Machine Learning es la capacidad de enseñar a un computador. Una definición formal podría ser:

&gt; Una maquina se dice que aprende de la **Experiencia E**, respecto a una clase de **Tarea T** medido por una medida de **Performance P** si su performance de la **Tarea T** medido a través de **P** mejora con la **Experiencia E**. 

*Tom Mitchell, 1997*

---


# Tipos de Modelamiento

.pull-left[

### Supervised Learning
  - Modelos de Regresión 
  - Modelos de Clasificación
    - Modelos Binarios
    - Modelos Multiclase
    - Modelos Multilabel

### Unsupervised Learning
  - Clustering
  - Reducción de Dimensionalidad
  - Factorization Machines
  ]
  
.pull-right[

### Semi Supervised Learning


### Reinforcement Learning
 - Autos autónomos
 - Robots autónomos
 - X Autónomo

]

---
class: center

# Flujo de un Problema de Machine Learning

&lt;img src="img/ml_flow.jpg" height="500" /&gt;

---

.left-column[

# Scikit Learn

&lt;img src="img/scikit_logo.png" width="300" /&gt;



]

.right-column[

* Es una librería de código abierto en Python diseñada para Machine Learning. 
* Nace como un proyecto de Google Summer of Code project, tiene más de 10 años de desarrollo y está auspiciada por:
  - Microsoft
  - Intel
  - Nvidia
  - Universidad de Columbia
  - Inria
  - BNP Paribas
  - entre otros.
* Su documentación es demasiado buena. Incluyendo claras instrucciones de cómo usar su API, además de códigos de ejemplo y la teoría asociada a cada modelo. Además todos los modelos suelen tener papers asociados citados en la documentación.
* Es sumamente estricta al momento de aceptar nuevos modelos. Suele exigir 3 años desde su publicación en papers más 200+ citas y uso masivo.

&gt; [`Scikit-learn`](https://scikit-learn.org/stable/index.html) está orientado a modelos predictivos del lado del ML, mientras que [`statsmodels`](https://www.statsmodels.org/dev/index.html) está orientado a la inferencia y  y modelos más del lado estadístico.


]
---

# Scikit Learn API


```python
X # estructura de datos de dos dimensiones, matriz de features
y # estructura de datos de una dimensión*, vector de target
```

.pull-left[

#### **Estimators**

```python
from sklearn.submodule import Estimator

estimator = Estimator(p_1, p_2,..., p_k)
estimator.fit(X,y)
estimator.predict(X)*
estimator.score(X,y)
```
]
.pull-right[

#### **Transformers**


```python
from sklearn.submodule import Transformer

transformer = Transformer(p_1,p_2,...,p_k)
transformer.fit(X,y)
transformer.transform(X)
transformer.fit_transform(X,y)
```
]

.footnote[

&lt;br&gt;
\* Para modelos de clasificación Multiclass o Multilabel este vector podría ser bidimensional también.

\* Algunos modelos poseen también un método .fit_predict(X)  
\* La API de `scikit-learn` es sumamente ordenada y **consistente** por lo que es fácil de entender/aprender.  
\* Normalmente para Estimators Supervisados existirá la versión `Classifier` y `Regressor`.

]


---

# Qué es un modelo?

Normalmente estamos acostumbrados a calcular funciones, donde dado un valor de X obtenemos un valor de y siempre y cuando conozcamos la función.

* `\(y = f(x)\)`
* `\(f(x) = x\)`
* `\(f(x) = x^2\)`
* `\(f(x) = log(x)\)`
* `\(f(x) = \sqrt{x}\)`
* `\(f(x) = blackbox\)`

En un modelo, nosotros conocemos los valores de entrada X y conocemos los valores de salida y, lo que no sabemos es `\(f(\cdot)\)`. Por lo tanto al modelar, lo que queremos encontrar es el valor de `\(f(\cdot)\)` tal que cuando le agreguemos X, obtengamos y.

&gt; En `scikit-learn` un modelo será la combinación de Estimators y Transformers con hiperparámetros óptimos que realicen una tarea T determinada.

---

# Ejemplos

.pull-left[
Determinar el precio de una casa dado que conozco: 
* N de baños,
* N de dormitorios
* Precio de Arriendo,
* Ubicación
* Barrio
* etc.

&gt; **Problema de Regresión**

]

.pull-right[
Determinar si una vacuna contra una enfermedad será efectiva o no si conocemos:
* Concentración de Antígenos,
* Resultados anteriores,
* Dosis
* etc

&gt; **Problema de Clasificación**

]

---

# Problemas de Regresión

Los problemas de Regresión son aquellos donde nuestra variable a predecir `\(y\)` es de tipo continua. 

.pull-left[
&lt;img src="img/regresion.png" width="500" /&gt;


]

.pull-right[
&lt;img src="img/modelo.png" width="800" /&gt;

]

&gt; NOTA: En este caso la experiencia **E** corresponde a los datos, la tarea **T** corresponde a un problema de Regresión y la métrica **P** podría corresponder al error promedio.



---

# La Regresión Lineal

.pull-left[

&lt;img src="img/regresion.png" width="700" /&gt;

]

.pull-right[

`$$f(X) = \sum_{i = 0}^p \beta_i X_i + \epsilon_i,\, p: \text{ Número de Features}$$`

Los valores de `\(\beta\)` se obtienen mediante un proceso de optimización, este método puede ser:

* Mínimos Cuadrados
* Stocastic Gradient Descent.
* etc.

En ambos métodos se busca minimizar una función de costo, de tal manera de encontrar `\(\beta_i\)` óptimos que minimizen el error.

`$$J = \sum_{i}^n(y_i - \hat{y_i})^2, \, n: \text{Número de Observaciones}$$`
]

&gt; NOTA: Una función de Costo refleja el error asociado al modelo en cuestión. (ERROR DE AJUSTE)

---

# Aplicación en Scikit-Learn

.pull-left[

```python
import pandas as pd
df = pd.read_csv('mtcars.csv',index_col = 0)
X = df.drop(columns = 'mpg')
y = df.mpg
```

]

.pull-right[

&lt;img src="img/mtcars.png" width="700" /&gt;

]


```python
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(X,y)
lr.score(X,y)
```
--

&gt; `0.8690157644777647`

[Ver Docs](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)

.footnote[
* `.score()` devuelve el `\(R^2\)` Score para modelos de regresión. Esta métrica va entre 0 y 1, siendo 0 el peor ajuste y 1 un ajuste perfecto.
]

---

# Aplicación en Scikit-Learn

* Es posible extraer cada uno de los coeficientes obtenidos al optimizar por mínimos cuadrados. `\(\beta_i\)`


```python
lr.coef_
```

--

&gt; `array([-0.11144048,  0.01333524, -0.02148212,  0.78711097, -3.71530393,
        0.82104075,  0.31776281,  2.52022689,  0.65541302, -0.19941925])`
        
--
        
* Además se puede calcular el Intercepto: `\(\beta_0\)`


```python
lr.intercept
```
--

&gt; `12.30337415599627`


--

## ¿Cuál es la interpretación de cada `\(\beta_i\)`?

---

# Bias-Variance Trade-Off

.pull-left[

&lt;img src="img/bias-variance.jpeg" width="700" /&gt;

]

.pull-right[

* **Bias/Sesgo**: Corresponde a la simplificación de los supuestos que el modelo hace para que el modelo se ajuste al Target de mejor manera.

* **Variance/Varianza**: Corresponde a las variaciones de la estimación dependiendo de cómo se entrene.

&lt;img src="img/regresion.png" width="481" height="300" /&gt;

]

---

# Bias-Variance Trade-Off

.pull-left[

#### Underfitting/Subajuste
&lt;img src="img/regresion.png" width="481" height="200" /&gt;

]

.pull-right[

#### Overfitting/Sobreasjustado
&lt;img src="img/regresion.png" width="481" height="200" /&gt;

]

--
.center[


&lt;img src="img/regresion.png" width="481" height="200" /&gt;

]



---

# Honest Assessment

Cuando se quiere que alguien aprenda, normalmente se enseña contenido/materia (**E**) para realizar una tarea (**T**) y luego se mide (**P**). Pero nunca se mide lo aprendido con respuestas que ya viste.

En los modelos, se debe aplicar exactamente lo mismo. El modelo debiera ser entrenado con `\(E_{train}\)` y luego medido con `\(E_{test}\)` que no haya visto previamente demodo de medir de manera honesta si **'aprendió'** o **'memorizó'**.

.center[
&lt;img src="img/train_test.png" width="840" height="350" /&gt;
]

---
# Implementación en Scikit-Learn



```python
from sklearn.model_selection import train_test_split

# pueden escribir este código en una sóla línea
X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = 'mpg'), df.mpg, 
  test_size = 0.3, random_state = 123)
```
* Esto genera 2 subsets de Train y Test, uno para entrenar y el otro para medir performance. Luego para modelar, el código cambia levemente.


```python
from sklearn.linear_model import LinearRegression
lr = LinearRegression() # crea el modelo
lr.fit(X_train,y_train) # entrenamiento en el train_set
lr.score(X_test,y_test) # evaluación en el test_set
```

--

&gt; `0.5347705850352262`

&gt; **NOTA**: Es posible apreciar que la métrica de performance disminuyó drásticamente, ya que en este caso se está realizando una evaluación honesta de la performance en un dataset que nunca ha visto.

---

# Ejercicios

Ajuste una Regresión Lineal y mida su performance en los siguientes datasets:

&gt; NOTA: Utilice siempre un `random_state = 123`

.pull-left[

#### Diabetes Dataset


```python
from sklearn.datasets import load_diabetes
diabetes = load_diabetes(as_frame = True)
X = diabetes.data
y = diabetes.target
```
* Qué se está prediciendo?
* Genere un split del 30% test.
* Calcule cuál es la variable que más aporta al target y la que más resta.
{{content}}

]

.pull-right[

#### Boston Dataset


```python
from sklearn.datasets import load_boston
X,y  = load_boston(return_X_y  = True)
names = load_boston()['feature_names']
```
* Qué se está prediciendo?
* Genere un split del 20% test.
* Calcule cuál es la variable que más aporta al target y la que más resta.

]


---

# Ejercicios

.pull-left[

&gt; `Score Train: 0.5174979976746197`
&gt; `Score Test: 0.5078285584893742`
&gt; `Max coef: s5`  
&gt; `Min coef: s1`

]


.pull-right[

&gt; `Score Train: 0.7559380876016175`  
&gt; `Score Test: 0.6592466510354097`
&gt; `Max coef: RM`  
&gt; `Min coef: NOX`

]

--


```python
# Solución Diabetes

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 123)

lr = LinearRegression()
lr.fit(X_train, y_train)
print('Score Train:', lr.score(X_train, y_train))
print('Score Test:', lr.score(X_test, y_test))
ind_pos = np.argmax(lr.coef_)
ind_neg = np.argmin(lr.coef_)
print('Max coef:', X.columns[ind_pos])
print('Min coef:', X.columns[ind_neg])
```

---

# Bias-Variance Tradeoff

.center[
&lt;img src="img/model_complexity.png" width="900" /&gt;
]

---

# Métricas de Performance (Regresión)

* **Scorers**: Los scorers indican ajuste del modelo, normalmente más alto es mejor
* **Errors/Losses**: Indican la diferencia entre el valor predicho y el valor real, en este caso, un valor más bajo es mejor.

### MSE: Mean squared error

.pull-left[

`$$MSE = \frac{1}{N} \sum_{i= 1}^{N}(y_i-\hat{y_i})^2$$`


**Pros**:
* Métrica fácil de optimizar.
* Simple de entender.
* Castiga los errores grandes de manera más severa mientras que errores pequeños de manera más suave.
]

.pull-right[


```python
from sklearn.metrics import mean_squared_error

mean_squared_error(y_test, y_pred)
```
**Contras**:
* Métrica en unidades cuadráticas, dificil de interpretar.
* Es sensible a los valores extremos.

]



---

# Métricas de Performance (Regresión)

### RMSE: Root Mean squared error

Corresponde a una variación del MSE manteniendo casi todas sus características.

`$$RMSE = \sqrt{MSE} =  \sqrt{\frac{1}{N} \sum_{i= 1}^{N}(y_i-\hat{y_i})^2}$$`
* Actualmente no existe una implementación directa en Python por lo que se calcula de la siguiente manera:


```python
from sklearn.metrics import mean_squared_error

np.sqrt(mean_squared_error(y_test, y_pred))
```

* **Pro**: Se mide en las mismas unidades que la variable a predecir. Por lo tanto es interpretable como un error promedio.

---

# Métricas de Performance (Regresión)

### MAE: Mean Absolute Error

`$$MAE = \frac{1}{N}\sum_{i =1}^{N}|y_i-\hat{y_i}|$$`

```python
from sklearn.metrics import mean_absolute_error

mean_abolute_error(y_test, y_pred)
```

En este caso se utiliza el valor absoluto y todos los valores son penalizados de manera proporcional.

**Pro**
* Es una métrica muy robusta en contra de los valores extremos.


---

# Métricas de Performance (Regresión)

### `\(R^2\)` Score: 

Corresponde al porcentaje de Ajuste de un modelo. Varía entre 0 y 1.

`$$R^2 = 1 - \frac{\frac{1}{N}\sum_{i=1}^N(y_i - \hat{y_i})^2}{\frac{1}{N}\sum_{i=1}^N(y_i - \overline{y})^2}= 1- \frac{MSE}{\frac{1}{N}\sum_{i=1}^N(y_i - \overline{y})^2}$$`


```python
from sklearn.metrics import r2_score

r2_score(y_test, y_pred)
```

**Pros**:
* Es una métrica que permite medir por sí sola.

**Contras**: Se ve afectada por lo complejidad del modelo, por lo que en ML no es tan usada ya que todos los modelos son relativamente complejos.


.footnote[* En `scikit-learn` el `\(R^2\)` puede ser un valor negativo para demostrar un pésimo ajuste.]
---

# Métricas de Performance (Regresión)

#### MSPE: Mean Squared Percentage Error* 
Corresponde al MSE pero de tipo porcentual


#### MAPE: Mean Absolute Percentage Error* 

Corresponde al MAE de tipo Porcentual

#### Median Absolute Error

Error similar al MAE pero utilizando la mediana para agregar los valores.

#### Mean Squared Log Error

MSE pero en escala logarítmica.


[Ver docs](https://scikit-learn.org/stable/modules/model_evaluation.html)


.footnote[*Estas métricas no se encuentran implementadas actualmente en `scikit-learn` de manera directa, pero pueden ser métricas útiles al momento de evaluar un modelo.]


---

# Ejercicios

&gt; NOTA: Utilice siempre un `random_state = 123`

Utilice los datasets anteriores de Diabetes y Boston para relizar lo siguiente:

* Mostrar la Predicción de los primeros 10 casos del test set en conjunto con los valores reales.
  - Utililce el método `.predict()` para calcular `y_pred` en el test set.
* Calcular las métricas de `\(R^2\)`, MSE, RMSE y MAE para el train_set como para el test_set.
* Qué se puede concluir a partir de aquello?

* Muestre qué coeficientes son más importantes en magnitud y su contribución al modelo.
* Cuánto vale el Intercepto para cada modelo?


---

# Ejercicios

&gt; `Diabetes:`  
&gt; `R2 Train: 0.5174979976746197`  
&gt; `R2 Test 0.5078285584893742`  
&gt; `MSE Train: 2854.168253060431`  
&gt; `MSE Test: 2926.8005772468828`  
&gt; `RMSE Train: 53.424416263169704`  
&gt; `RMSE Test: 54.099912913487046`  
&gt; `MAE Train: 43.03474379534746`  
&gt; `MAE Test: 44.48057319064366` 

--

&gt; `Boston:`  
&gt; `R2 Train: 0.7647156501433012`  
&gt; `R2 Test 0.6485645742370703`  
&gt; `MSE Train: 20.184336639873155`  
&gt; `MSE Test: 28.40585481050824`  
&gt; `RMSE Train: 4.492698146979514`  
&gt; `RMSE Test: 5.329714327288869`  
&gt; `MAE Train: 3.1219958710301117`  
&gt; `MAE Test: 3.6913626771162673`  





    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "solarized-dark",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
